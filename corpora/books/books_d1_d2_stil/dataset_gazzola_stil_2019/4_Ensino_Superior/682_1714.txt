 Um valor do coeficiente de determinação igual a (ou próximo de) 0 significa um mau ajuste da recta de regressão aos dados. Henriques (2009, p. 35) considera que neste caso se está perante uma relação não linear entre as duas variáveis. Henriques (2009, p. 35) define ainda o coeficiente de correlação simples, formula_18, dado por:
formula_19
Onde o sinal de positivo ou negativo é o mesmo que o sinal do declive formula_7. O valor de formula_18 pode tomar qualquer valor no intervalo de -1 a 1, onde r = 1 ou r = -1 indicam uma relação linear perfeita (positiva e negativa, respectivamente) entre as duas variáveis, r = 0 indica uma relação não linear entre as duas variáveis ou mesmo a inexistência de uma relação entre as mesmas, e r < 0 indica uma relação linear negativa e r > 0 indica uma relação linear positiva entre as variáveis formula_1 e formula_2. De acordo com Henriques (2009, p. 16), a regressão linear deve ser utilizada com cautela, pois um conjunto de pontos mostra a existência de uma relação linear entre as duas variáveis apenas para os valores do conjunto de dados. Para valores fora desse conjunto, não há nenhuma prova de linearidade. Pode ser incorrecto utilizar a recta de regressão estimada para prever valores da variável dependente correspondentes a valores da variável independente que estão fora do âmbito dos dados recolhidos. Adnan et al. (2003, p. 30) refere que podem existir termos de erro que não tem distribuição normal, nem estão independentemente distribuídos. Nestes casos, poderá ocorrer distorção da recta de regressão e, consequentemente, valores dos parâmetros de regressão com erros. Estas aberrações ("outliers") que parecem inconsistentes com o restante conjunto de dados podem ter uma grande influência na análise estatística e, consequentemente, na recta de regressão estimada. Para Rosado (2009, p. 13) o "outlier" é frequentemente o valor máximo ou mínimo da amostra, embora a discordância de valores possa não se manifestar exclusivamente nos extremos. Para Maia (2004, p. 2), quando duas variáveis são correlacionadas, podem-se prever valores de uma variável em função do valor da outra variável, embora isso possa levar à conclusão errada de que uma variável é verdadeiramente a causa da variação da outra. De acordo com esse autor, não é possível provar uma relação de causa-efeito entre ambas as variáveis, mesmo havendo uma expressão matemática que relacione uma variável com a outra. Há, portanto, três explicações plausíveis para a existência de um modelo matemático que relaciona ambas as variáveis:
Maia (2004, p. 2) dá o seguinte exemplo para a terceira hipótese: há estudos que revelam alta correlação entre a variação do comprimento das saias das senhoras e a as movimentações da bolsa de Nova Iorque, ou entre os nascimentos na Inglaterra e a produção de gusa nos Estados Unidos.