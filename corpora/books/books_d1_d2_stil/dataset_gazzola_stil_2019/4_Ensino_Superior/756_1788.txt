 Finalmente, Hadoop requer um código de configuração que identifique para o sistema as funções a serem usadas, os arquivos de entrada e saída com seus tipos, etc. Essas informações são definidas por um objeto de configuração que é construído para esse fim como na listagem a seguir. As linhas 8 e 9 identificam as classes que definem as operações de mapeamento e redução. As linhas 11 e 12 associam arquivos armazenados no HDFS à entrada e saída do programa. O nome usado como entrada pode ser o de um arquivo específico ou de um diretório contendo diversos arquivos, que serão todos processados da mesma forma, potencialemente em paralelo. Já o nome usado para a saída deve sempre ser o de um diretório vazio, onde serão criados arquivos para cada nó de processamento que executará a função de redução. O tipo dos pares chave/valor de saída é definido pelos comandos nas linhas 5 e 6. Com os comandos usados, a saída será gerada como arquivo texto, com um caractere de tabulação separando a chave do valor em cada linha. Como não há comandos semelhantes para a entrada, o tipo assumido é o de arquivo de texto simples. O sistema oferece também a opção de tratar a entrada como um arquivo texto com chaves e valores separados por um caractere de tabulação (como o gerado pela saída do programa), ou como um arquivo com registros complexos, caso em que o programador deverá fornecer uma classe de leitura adequada. Neste último caso há detalhes que precisam ser tratados em relação ao processamento de registros que ultrapassam o limite de um bloco do arquivo no HDFS. Este e outros detalhes da interface de programação podem ser encontrados no tutorial da Yahoo! . Ao se executar o método "runJob" do objeto de configuração que descreve a aplicação (linha 14), o ambiente de tempo de execução do Hadoop passa a executar a tarefa. Os passos envolvidos nesse processo são descritos a seguir.