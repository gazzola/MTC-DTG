 Isso significa que nosso arquivo é separado em CHUNKS de dados e cada chunk é copiado em dois diferentes nós. Observe que cada chunk é completo, isto é, contém linhas completas do arquivo original. Isto é importante para mantermos o cálculo em paralelo e independente das verossimilhanças dos conjuntos de lançamentos e as prováveis probabilidades de cada moeda. A execução de programas em ambientes distribuídos pode trazer benefícios se o tempo para iniciação dos programas e troca de dados não forem overhead maior do que o ganho com a paralelização da tarefa. A estratégia MapReduce é reduzir ao máximo a troca de dados entre os nós que trabalham para realizar uma tarefa. Neste paradigma, o objetivo é levar o processamento até onde os dados estão e não o inverso. Portanto, inicialmente, quando se transfere os arquivos para o HFS eles são distribuídos em chunks pelos nós disponíveis no cluster. O processamento de Map ocorre em cada um dos nós que já possuem parte dos dados. Dados são transferidos somente no caso de queda de máquina e/ou grave desbalanceamento. Por fim, terminadas as tarefas de Map, os dados resultantes são transferidos para os worker que estão rodando as tarefas de Reduce. Seguindo a estratégia MapReduce, o recomendável é que estes dados não sejam complexos e pequenos o suficiente para não causar overhead na rede. No caso da nossa tarefa, esses dados são somente as novas contagens geradas pela verossimilhança entre o conjunto de lançamentos e a probabilidade P(cara) de cada moeda que podem ser expressas utilizando o tipo Double. Utilizamos o Hadoop File System versão 1.03 para armazenamento dos nosso dados de forma distribuída e programas nossa estratégia de MapReduce utilizando a API do Apache Hadoop. O Hadoop File System é um sistema distribuído, escalável, portável e open-source escrito em Java que suporta a execução de aplicações que exigem uma quantidade grande dados de forma distribuída. Ele foi inspirado nos artigos escritos pela Google descrevendo o Google File System que também implementa o paradigma de MapReduce.