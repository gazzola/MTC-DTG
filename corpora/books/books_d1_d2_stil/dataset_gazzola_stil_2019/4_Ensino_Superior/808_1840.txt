 No artigo entitulado “Google News Personalization: Scalable Online Collaborative FIltering” onde eles utilizam o "Expectation Maximization" para encontrar os parâmetros de máxima verossimilhança para o modelo em questão. Eles definem e isolam propriamente as fases E e M do algoritmo dentro do modelo e observam que a execução do algoritmo, para o volume de dados em questão é inviável (na época cerca de 80GiB de memória primária seria necessário). Dessa maneira eles separam usuários e itens (objetos em questão) e mapeam a etapa E para a etapa "Map", e a M para a etapa "Reduce". Na realidade, abordagem bastante similar é utilizada em nossa estudo de paralelização e distribuição da computação. Tomando o exemplo que será utilizado durante o trabalho, está apresentado na tabela abaixo o passo E do algoritmo de Maximização de Expectativas. É importante notar que cada uma das linhas representa um lançamento com uma moeda desconhecida. As duas tabelas seguintes apresentam a distribuição de probabilidade definida sobre ambas as moedas e as duas últimas representam o número de caras (H) e coroas (T) para a distribuição computada. É importante notar que cada linha encapsula todas as informações necessárias (juntamente com os parâmetros estimados na iteração anterior) e pode ser calculada de maneira independente. Essa é a oportunidade para a paralelização dessa computação, extremamente adequada para a etapa Map, no modelo de programação MapReduce. Após cada uma das probabilidades terem sido calculadas é a hora de estimar os novos parâmetros (os viéses) para cada uma das moedas. Isso se dá com a soma das duas últimas colunas e a aplicação do MLE. Novamente é fácil notar que, com o resultado da fase Map, basta aplicar a etapa Reduce do modelo MapReduce para obtermos os novos parâmetros e realizar outra etapa de MapReduce. Não existem necessidades ou observações especiais de acesso aos dados além do já citado anteriormente, de que cada nó irá guardar uma fração dos dados que é de sua competência. Um único detalhe especial é de que o valor para os parâmetros da iteração anterior deve estar disponível para todos os nós.