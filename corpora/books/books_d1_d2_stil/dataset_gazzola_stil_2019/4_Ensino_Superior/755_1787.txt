 Considerando-se as diferenças de implementação, no caso do Hadoop vale a pena analisar detalhadamente o código realmente utilizado para a aplicação codice_1, ao invés de apenas um pseudo-código mais abstrado. O código apresentado a seguir foi obtido do tutorial sobre Hadoop da Yahoo! , uma fonte de consulta altamente recomendada para detalhes sobre elementos de instalação, programação e execução no Hadoop. Outra fonte que merece menção é o tutorial da Apache Software Foundation . A função codice_2 define os tipos dos pares chave/valor de entrada e saída (linha 2). Neste caso, para um arquivo texto, Hadoop entrega cada linha com uma chave que corresponde à posição (em bytes) do começo da linha (texto) em relação ao começo do arquivo, daí usar um inteiro longo. A chave produzida pelo map será uma palavra (texto) e o valor será um inteiro. Os tipos terminados em "Writable" são usados pelo Hadoop para lidar com a leitura e escrita dos mesmos nos arquivos do HDFS corretamente (serialização e desserialização). Outros detalhes de configuração são a definição do tipo de arquivo de saída ("OutputCollector") que receberá os pares chave/valor do tipo indicado (linha 8). A classe "Reporter" é usada para gerar dados de acompanhamento da execução para o sistema. O código realmente responsável pelo processamento está entre as linhas 10 e 15: o valor recebido como entrada é transformado em um "string", que é dividido em "tokens", que são enviados para a saída com a chamada de "output.collect". O código do redutor, apresentado a seguir, também exige detalhes de declaração de tipos de entrada e saída, que neste caso são iguais: palavra(texto)/inteiro (linha 2). Como a função de redução recebe uma lista de valores, o segundo tipo é um iterador sobre a lista de valores associados a cada chave (linha 4). Os outros elementos da definição são semelhantes ao caso do "map". O núcleo de processamento está entre as linhas 7 e 11 nesse caso: o "loop" itera sobre todos os valores recebidos para cada palavra (todos valendo um, nesse caso, já que não foi definido um "combiner") e o valor final da contagem para cada palavra é lançado com um "output.collect".