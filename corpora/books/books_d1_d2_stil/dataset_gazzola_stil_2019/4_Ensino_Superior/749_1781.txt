 Alterações não são possíveis depois que um dado é escrito e o objetivo é tornar eficiente padrões de acesso que percorram todo o arquivo de cada vez. Para isso, arquivos são dividos em blocos grandes (usualmente 64 MB), que são distribuídos pelos discos de diversas máquinas do sistema e replicados para aumentar a disponibilidade dos mesmos. No GFS (e HDFS), cada sistema de arquivos tem uma máquina escolhida como servidor do espaço de nomes ("namenode"), responsável também por armazenar os metadados de cada arquivo. A estrutura de arquivos do GFS é isolada e independente da árvore de diretórios usual acessada por cada máquina. Os acessos se dão através de uma biblioteca especial e não através da interface de chamadas de sistema. Ao criar um arquivo, um cliente registra seu nome com o "namenode" e começa a escrever os blocos em máquinas escolhidas no mesmo "rack" em que executa o processo escritor (para aproveitar a melhor banda entre máquinas no mesmo "rack"). Uma vez escrita essa primeira cópia o cliente continua seu processamento, enquanto o servidor de armazenamento do GFS que recebeu o bloco (denominado "datanode") passa a replicar o mesmo em um outro "datanode", escolhido normalmente em um outro "rack" (para evitar problemas com falhas que afetem um "rack" inteiro). Usualmente cada bloco é replicado três vezes (apesar desse número poder ser configurado pelo usuário para cada arquivo) e uma terceira cópia é feita então pelo segundo datanode para um outro "datanode" no mesmo "rack" (de novo, aproveitando a banda local). Ao abrir um arquivo para leitura, o cliente se comunica como "namenode" e recebe dele a lista de blocos do arquivo, com a identificação dos namenodes que armazenam cada bloco. O cliente pode então escolher de qual "namenode" requisitar os dados de que necessita baseado em critérios de proximidade. Dessa forma, vários clientes podem escolher ler partes diferentes do arquivo a partir de "datanodes" diferentes, aumentando a banda de leitura dos dados. Periodicamente, processos administrativos verificam a disponibilidade de cada "datanode" e os blocos armazenados em cada um, comandando novas cópias ou movendo blocos entre nós para garantir o balanceamento entre eles. Esses processos também cuidam de comandar a redistribuição de blocos quando novos "datanodes" são acrescentados ao sistema, ou comandar novas replicações quando algum nó falha. Esses são elementos importantes do ambiente normalmente utilizado para processamento de dados massivos. A seção a seguir discute os principais aspectos de escalabilidade e eficiência que precisam ser considerados nesse caso, para então discutirmos nas seções seguintes os modelos de processamento disponíveis.