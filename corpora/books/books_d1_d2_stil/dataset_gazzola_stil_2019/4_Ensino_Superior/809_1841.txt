 Aqui novamente não há detalhes especiais a serem mencionados. Cada bloco de arquivo, que foi distribuído para cada nó contém todas as informações necessárias para o processamento que ele deve realizar. Dessa maneira, não existe a possibilidade de "dead-locks" ou de "starvation", ou qualquer outro dano causado pela ociosidade em função de comunicação não bem realizada. Os únicos dados recebidos a cada iteração do processamento distribuído são os parâmetros, e os enviados, os números esperados de caras e coroas para a função de distribuição definida. Obviamente, funções de probabilidade calculadas no passo E devem ser repassadas no passo Reduce, mas esse detalhe é implícito ao modelo de programação MapReduce. A linha do tempo abaixo ilustra a linha do tempo do processamento do algoritmo de Maximização de Expectativas, como discutido anteriormente. Cada nó irá receber um ou mais linhas do dado bruto, lembrando que cada linha corresponde à um lançamento das moedas. Isso é possível graças a independência do cálculo dos valores para a distribuição de probabilidade, após a obtenção do primeiro valor para os parâmetros (feito nesse trabalho de maneira aleatória). Essa tarefa é coordenada pela etapa Map. Em seguida, a etapa Reduce, se encarrega de agregar os valores computados para os valores esperados para a cada distribuição avaliada, para por fim, estipular novos parâmetros e recomeçar o ciclo MapReduce até que haja conversão para os valores dos parâmetros. A solução encontrada para distribuir o algoritmo entre vários nós é bastante direta: calcular a verossimilhança de cada conjunto de lançamentos em paralelo através do map e para cada moeda calcular a nova distribuição de probabilidades a partir da verossimilhança encontrada para moeda. Contamos com somente um arquivo de entrada para alimentar o algorimto de maximização de expectativas. Neste arquivo - com tamanho que pode chegar 1gb - cada linha representa um conjunto de lançamentos feito com uma moeda desconhecida. Inicialmente, transferimos o arquivo para o HFS (Hadoop File System) escolhendo o nível de redundância igual 2.